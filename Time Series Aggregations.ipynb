{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Aggregations on Timeseries Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While writing this  blog article, I took a break from working on lots of time series data with Pandas. I was performing lots of aggregations and feature engineering tasks on top of a Credit Card Transaction dataset. I want to share with you some of my insights in usefull operations for performing explorative data analysis or preparing a times series dataset to perform some machine learning task on top of it. \n",
    "\n",
    "In this blog post you will learn:\n",
    "\n",
    "* How to load time series data from a csv \n",
    "* What the rolling operation on a dataframe is what is it usefull for\n",
    "* How to combine group by operation and rolling operation on a pandas dataframe\n",
    "* Some examples for transformations using the two operations above that will be usefull for you in practice\n",
    "* Some Hints in how to parellize these operations to be using all you CPU Cores.\n",
    "\n",
    "(Hint you can find a Jupyter notebook containing all the code and the toy data mentioned inthis blog post here: TODO)\n",
    "\n",
    "Let us start with loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading timeseries data from a CSV is straight forward in pandas. We simply use the read csv comand and define the `Datetime` column as an index column and also give pandas the hint that it should parse the `Datetime` column as pandas Datetime field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"time_series_example.csv\",index_col=\"Datetime\",parse_dates=[\"Datetime\"])\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Card ID</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>1</td>\n",
       "      <td>72.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2</td>\n",
       "      <td>186.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>1</td>\n",
       "      <td>29.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08</th>\n",
       "      <td>2</td>\n",
       "      <td>131.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>1</td>\n",
       "      <td>30.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>2</td>\n",
       "      <td>145.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>1</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>2</td>\n",
       "      <td>200.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>1</td>\n",
       "      <td>189.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>2</td>\n",
       "      <td>567.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Card ID  Amount\n",
       "Datetime                   \n",
       "2019-12-01        1   72.70\n",
       "2019-12-02        2  186.78\n",
       "2019-12-05        1   29.20\n",
       "2019-12-08        2  131.10\n",
       "2019-12-12        1   30.30\n",
       "2019-12-17        2  145.20\n",
       "2019-12-18        1   43.70\n",
       "2019-12-23        2  200.10\n",
       "2019-12-26        1  189.90\n",
       "2019-12-27        2  567.20"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that we loaded sucessfully the data. Let's take a brief look at it. For all TimeSeries operations it is critical that pandas loaded the index correctly as an `DatetimeIndex` you can validate this by typing `df.index` and see the correct index. Next two the `Datetime` index column, that refers to the timestamp of a credit card purchase(transaction), we have a `Card ID` column refering to an ID of a Credit Card and an `Amount` column, that ..., well indicates the amount in Dollar of the purchase with the card at the specified time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-12-01', '2019-12-02', '2019-12-05', '2019-12-08',\n",
       "               '2019-12-12', '2019-12-17', '2019-12-18', '2019-12-23',\n",
       "               '2019-12-26', '2019-12-27'],\n",
       "              dtype='datetime64[ns]', name='Datetime', freq=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Window on Timeseries with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we're interested in is what is 7 day rolling mean of the credit card transaction amounts. What this means in this example is quite easy to explain. For every single transaction we look 7 days back, collect all transactions that fall in this range and get the average of the `Amount` column. Luckily this is very easy to achieve with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime\n",
       "2019-12-01     72.700000\n",
       "2019-12-02    129.740000\n",
       "2019-12-05     96.226667\n",
       "2019-12-08    115.693333\n",
       "2019-12-12     80.700000\n",
       "2019-12-17     87.750000\n",
       "2019-12-18     73.066667\n",
       "2019-12-23    129.666667\n",
       "2019-12-26    195.000000\n",
       "2019-12-27    319.066667\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rolling('7D').Amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information might by quite interesting in some use cases, for credit card transaction use cases we usually are interested in the average revenue, the amount of transaction, etc... per customer in some time window.\n",
    "\n",
    "## Combining grouping and rolling window timeseries aggregations with pandas\n",
    "\n",
    "We can achieve this by grouping our dataframe by the columns `Card ID` and then perfom the rolling operation on every group individually. Here is how we get the amount of transactions in the last 7 days for any transaction for every Card seperately. (Hint we store the result in a dataframe to later merge it back to the orignal df to get on comprehensive dataframe with all the relevant data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Card ID  Datetime  \n",
       "1        2019-12-01    1.0\n",
       "         2019-12-05    2.0\n",
       "         2019-12-12    1.0\n",
       "         2019-12-18    2.0\n",
       "         2019-12-26    1.0\n",
       "2        2019-12-02    1.0\n",
       "         2019-12-08    2.0\n",
       "         2019-12-17    1.0\n",
       "         2019-12-23    2.0\n",
       "         2019-12-27    2.0\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Card ID\").rolling('7D').Amount.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Transaction Count 7D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Card ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Transaction Count 7D\n",
       "Card ID Datetime                        \n",
       "1       2019-12-01                   1.0\n",
       "        2019-12-05                   2.0\n",
       "        2019-12-12                   1.0\n",
       "        2019-12-18                   2.0\n",
       "        2019-12-26                   1.0\n",
       "2       2019-12-02                   1.0\n",
       "        2019-12-08                   2.0\n",
       "        2019-12-17                   1.0\n",
       "        2019-12-23                   2.0\n",
       "        2019-12-27                   2.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7d_count = pd.DataFrame(df.groupby(\"Card ID\").rolling('7D').Amount.count())\n",
    "df_7d_count = df_7d_count.rename(columns={\"Amount\":\"Transaction Count 7D\"})\n",
    "df_7d_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we might also be interested in a average transaction volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7d_mean_amount = pd.DataFrame(df.groupby(\"Card ID\").rolling('7D').Amount.mean())\n",
    "df_7d_mean_amount = df_7d_mean_amount.rename(columns={\"Amount\":\"Mean Amount 7D\"})\n",
    "df_7d_mean_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the result in one comprehensive DataFrame\n",
    "In order to have an overview of what features we have, we can merge now simply the two created dataframe back to an copy of the orignal dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Card ID</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mean Amount 7D</th>\n",
       "      <th>Transaction Count 7D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Card ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>1</td>\n",
       "      <td>72.70</td>\n",
       "      <td>72.70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>1</td>\n",
       "      <td>29.20</td>\n",
       "      <td>50.95</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>1</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>1</td>\n",
       "      <td>43.70</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>1</td>\n",
       "      <td>189.90</td>\n",
       "      <td>189.90</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2</td>\n",
       "      <td>186.78</td>\n",
       "      <td>186.78</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08</th>\n",
       "      <td>2</td>\n",
       "      <td>131.10</td>\n",
       "      <td>158.94</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>2</td>\n",
       "      <td>145.20</td>\n",
       "      <td>145.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>2</td>\n",
       "      <td>200.10</td>\n",
       "      <td>172.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>2</td>\n",
       "      <td>567.20</td>\n",
       "      <td>383.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Card ID  Amount  Mean Amount 7D  Transaction Count 7D\n",
       "Card ID Datetime                                                         \n",
       "1       2019-12-01        1   72.70           72.70                   1.0\n",
       "        2019-12-05        1   29.20           50.95                   2.0\n",
       "        2019-12-12        1   30.30           30.30                   1.0\n",
       "        2019-12-18        1   43.70           37.00                   2.0\n",
       "        2019-12-26        1  189.90          189.90                   1.0\n",
       "2       2019-12-02        2  186.78          186.78                   1.0\n",
       "        2019-12-08        2  131.10          158.94                   2.0\n",
       "        2019-12-17        2  145.20          145.20                   1.0\n",
       "        2019-12-23        2  200.10          172.65                   2.0\n",
       "        2019-12-27        2  567.20          383.65                   2.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = df.copy()\n",
    "result_df = result_df.merge(df_7d_mean_amount,left_index=True, right_index=True)\n",
    "result_df = result_df.merge(df_7d_count,left_index=True, right_index=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks already quite good let us just add one more feature to get the average amount of transactions in 7 days by card. Therefore we have now simply group by the `Card ID` again and then get the average of the `Transaction Count 7D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean 7D Transaction Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Card ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean 7D Transaction Count\n",
       "Card ID                           \n",
       "1                              1.4\n",
       "2                              1.6"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7d_mean_count = pd.DataFrame(result_df[\"Transaction Count 7D\"].groupby(\"Card ID\").mean())\n",
    "df_7d_mean_count = df_7d_mean_count.rename(columns={\"Transaction Count 7D\":\"Mean 7D Transaction Count\",\"Card ID\":\"Card\"})\n",
    "df_7d_mean_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have here now the need of joining two datasets with different indices we use the inner join then pandas picks automatically which index level we want to use and we see that now have the new column `Mean 7D Transcation Count`. We could add like this many different features to the dataset, e.g. like the maximum 7 Days Rolling Amount, minimum, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Card ID</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Mean Amount 7D</th>\n",
       "      <th>Transaction Count 7D</th>\n",
       "      <th>Mean 7D Transaction Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Card ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>1</td>\n",
       "      <td>72.70</td>\n",
       "      <td>72.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>1</td>\n",
       "      <td>29.20</td>\n",
       "      <td>50.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>1</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>1</td>\n",
       "      <td>43.70</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>1</td>\n",
       "      <td>189.90</td>\n",
       "      <td>189.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>2</td>\n",
       "      <td>186.78</td>\n",
       "      <td>186.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08</th>\n",
       "      <td>2</td>\n",
       "      <td>131.10</td>\n",
       "      <td>158.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>2</td>\n",
       "      <td>145.20</td>\n",
       "      <td>145.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>2</td>\n",
       "      <td>200.10</td>\n",
       "      <td>172.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>2</td>\n",
       "      <td>567.20</td>\n",
       "      <td>383.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Card ID  Amount  Mean Amount 7D  Transaction Count 7D  \\\n",
       "Card ID Datetime                                                            \n",
       "1       2019-12-01        1   72.70           72.70                   1.0   \n",
       "        2019-12-05        1   29.20           50.95                   2.0   \n",
       "        2019-12-12        1   30.30           30.30                   1.0   \n",
       "        2019-12-18        1   43.70           37.00                   2.0   \n",
       "        2019-12-26        1  189.90          189.90                   1.0   \n",
       "2       2019-12-02        2  186.78          186.78                   1.0   \n",
       "        2019-12-08        2  131.10          158.94                   2.0   \n",
       "        2019-12-17        2  145.20          145.20                   1.0   \n",
       "        2019-12-23        2  200.10          172.65                   2.0   \n",
       "        2019-12-27        2  567.20          383.65                   2.0   \n",
       "\n",
       "                    Mean 7D Transaction Count  \n",
       "Card ID Datetime                               \n",
       "1       2019-12-01                        1.4  \n",
       "        2019-12-05                        1.4  \n",
       "        2019-12-12                        1.4  \n",
       "        2019-12-18                        1.4  \n",
       "        2019-12-26                        1.4  \n",
       "2       2019-12-02                        1.6  \n",
       "        2019-12-08                        1.6  \n",
       "        2019-12-17                        1.6  \n",
       "        2019-12-23                        1.6  \n",
       "        2019-12-27                        1.6  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.join(df_7d_mean_count, how='inner')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What i find very useful we can now compute differences from the current 7 day window to the mean of all windows which can be for credit cards useful to find fraudulent transactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelize Group By Rolling Aggregation Operations\n",
    "\n",
    "For datasets with lots of different cards (or any other grouping criteria) and lots of transactions (or any other timeseries events) these operations can become very computational inefficient. The first obvious choice to is to scale up the operations on your local machine e.g. to use all the CPU Cores available in contrast to the pandas default to only use one CPU core. I find the little library pandarellel : https://github.com/nalepae/pandarallel Very usefull. I recently fixed a bug there that now it also works on time series grouped by and rolling dataframes.  Here is a small example of how to use the library to parallelize one operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandarallel\n",
      "  Cloning https://github.com/dice89/pandarallel.git to /private/var/folders/24/1t8_x_9d3n5b8zn0p4gwfb_w0000gn/T/pip-install-hlqcm0me/pandarallel\n",
      "  Running command git clone -q https://github.com/dice89/pandarallel.git /private/var/folders/24/1t8_x_9d3n5b8zn0p4gwfb_w0000gn/T/pip-install-hlqcm0me/pandarallel\n",
      "Collecting dill\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 102kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pandarallel, dill\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.4.2-cp36-none-any.whl size=17060 sha256=03e8e8ccba8a7a627c8688ef611abb2b26d78682dcad34d0c4982d3a225f297b\n",
      "  Stored in directory: /private/var/folders/24/1t8_x_9d3n5b8zn0p4gwfb_w0000gn/T/pip-ephem-wheel-cache-bub2k95c/wheels/04/49/7f/7d4feb4233df5499edccb6288874f4aba9bda650bdb0ddd378\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=6e214476cfd1ecb2fba9a9fcc9eed8f8e5f5f7b01f825a487d2694c57815ef16\n",
      "  Stored in directory: /Users/alexandermuller/Library/Caches/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "Successfully built pandarallel dill\n",
      "Installing collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.1.1 pandarallel-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+https://github.com/dice89/pandarallel.git#egg=pandarallel --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data tranfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1  2019-12-01     72.70\n",
       "   2019-12-05     50.95\n",
       "   2019-12-12     30.30\n",
       "   2019-12-18     37.00\n",
       "   2019-12-26    189.90\n",
       "2  2019-12-02    186.78\n",
       "   2019-12-08    158.94\n",
       "   2019-12-17    145.20\n",
       "   2019-12-23    172.65\n",
       "   2019-12-27    383.65\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Card ID\").rolling('7D').Amount.parallel_apply(np.mean,raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What pandarallel does is that is provides you with a new function `parallel_apply` on a dataframe that takes as an input a function that is then executed in parallel by all your CPU Cores by e.g. the group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To sum up we learned in the blog posts some methods to aggregate(group by, rolling aggregations) and transform (merging the data back together) timeseries data to either understand the dataset better or to prepare it for machine learning tasks. We also showed how to parallize some workloads to use all your CPUS on certain operations on your dataset in order to save time. \n",
    "\n",
    "I hope that this blog helped you to improve your workflow for time-series data in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
